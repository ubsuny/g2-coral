{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "occupied-meaning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# import libraries we need\n",
    "%pylab inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "import sys\n",
    "sys.path.append('./../simulation/')\n",
    "import Simulator\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acoustic-darwin",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the trained model\n",
    "trained_model = keras.models.load_model('g2model.h5')\n",
    "\n",
    "# get weights from the trained model\n",
    "def setup_pretrained_weights():\n",
    "    model= trained_model\n",
    "\n",
    "    _, pretrained_weights = tempfile.mkstemp('.tf')\n",
    "\n",
    "    model.save_weights(pretrained_weights)\n",
    "\n",
    "    return pretrained_weights\n",
    "\n",
    "pretrained_weights = setup_pretrained_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "american-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a base model\n",
    "def make_model(input_shape):\n",
    "    # input shape should be (time signal, 1)\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    # 1st con1d layer\n",
    "    #conv1 = keras.layers.Conv1D(filters=64, kernel_size=4, padding='valid', strides=1, activation='relu')(input_layer)\n",
    "    \n",
    "    # 2nd con1d layer\n",
    "    #conv2 = keras.layers.Conv1D(filters=64, kernel_size=4, padding='valid', strides=1, activation='relu')(conv1)\n",
    "\n",
    "    # 3rd con1d layer\n",
    "    #conv3 = keras.layers.Conv1D(filters=64, kernel_size=4, padding='valid', strides=1, activation='relu')(conv2)\n",
    "    \n",
    "    # maxpooling layer\n",
    "    #pool = keras.layers.MaxPool1D(pool_size=3, strides=1, padding='valid')(conv3) # keras.layers.GlobalAveragePooling1D()(conv3) #  # \n",
    "    \n",
    "    # flatten layer\n",
    "    flat = keras.layers.Flatten()(input_layer)\n",
    "    \n",
    "    # fully connected layer to output a binary vector\n",
    "    dense1 = keras.layers.Dense(2, activation='relu')(flat)\n",
    "    #dense2 = keras.layers.Dense(2, activation='relu')(dense1)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=dense1)\n",
    "\n",
    "base_model = make_model(input_shape=(200,1))\n",
    "quantize_model = tfmot.quantization.keras.quantize_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "union-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotate that only the Dense layers should be quantized.\n",
    "def apply_quantization(layer):\n",
    "    if isinstance(layer, tf.keras.layers.Dense):\n",
    "        return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
    "    elif isinstance(layer, tf.keras.layers.Conv1D):\n",
    "        return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
    "    elif isinstance(layer, tf.keras.layers.MaxPool1D):\n",
    "        return tfmot.quantization.keras.quantize_annotate_layer(layer)\n",
    "    return layer\n",
    "\n",
    "annotated_model = tf.keras.models.clone_model(\n",
    "    model = base_model,\n",
    "    clone_function= apply_quantization )\n",
    "\n",
    "q_aware_model = quantize_model(annotated_model)\n",
    "\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "african-cambridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 200, 1)]          0         \n",
      "_________________________________________________________________\n",
      "quantize_layer_10 (QuantizeL (None, 200, 1)            3         \n",
      "_________________________________________________________________\n",
      "quant_flatten_18 (QuantizeWr (None, 200)               1         \n",
      "_________________________________________________________________\n",
      "quant_dense_17 (QuantizeWrap (None, 2)                 407       \n",
      "=================================================================\n",
      "Total params: 411\n",
      "Trainable params: 402\n",
      "Non-trainable params: 9\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "optimum-suicide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.6931 - accuracy: 0.5398 - val_loss: 0.6931 - val_accuracy: 0.6000\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5572 - val_loss: 0.6931 - val_accuracy: 0.6000\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.6271 - val_loss: 0.6931 - val_accuracy: 0.6000\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5693 - val_loss: 0.6931 - val_accuracy: 0.6000\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5229 - val_loss: 0.6931 - val_accuracy: 0.6000\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5832 - val_loss: 0.6931 - val_accuracy: 0.6000\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5717 - val_loss: 0.6931 - val_accuracy: 0.6000\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4902 - val_loss: 0.6931 - val_accuracy: 0.6000\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.5908 - val_loss: 0.6931 - val_accuracy: 0.6000\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6931 - accuracy: 0.4857 - val_loss: 0.6931 - val_accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff8a5d05f40>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine tuning the mdoel\n",
    "xtrain_subset = x_train[0:100] # out of 60000\n",
    "ytrain_subset = y_train[0:100]\n",
    "\n",
    "q_aware_model.fit(xtrain_subset, ytrain_subset,\n",
    "                  batch_size=5, epochs=10, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cardiovascular-letter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as flatten_18_layer_call_and_return_conditional_losses, flatten_18_layer_call_fn, dense_17_layer_call_and_return_conditional_losses, dense_17_layer_call_fn, flatten_18_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as flatten_18_layer_call_and_return_conditional_losses, flatten_18_layer_call_fn, dense_17_layer_call_and_return_conditional_losses, dense_17_layer_call_fn, flatten_18_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwixwfqmw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpwixwfqmw/assets\n"
     ]
    }
   ],
   "source": [
    "# quantized the model\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "quantized_tflite_model = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "acting-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('qaware_dummy.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-optics",
   "metadata": {},
   "source": [
    "The above method **only works for supported layers contained model**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-friday",
   "metadata": {},
   "source": [
    "### *Try post-training quantization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "detected-glucose",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_7_zh2__/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_7_zh2__/assets\n"
     ]
    }
   ],
   "source": [
    "# use the trained model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(base_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# before convert it , need to add representative data sets to keep a good accuracy    \n",
    "def representative_dataset():\n",
    "      for data in x_repre:\n",
    "        yield [tf.dtypes.cast(data, tf.float32)]\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "medium-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Quantization/post-train.tflite', 'wb') as f:\n",
    "    f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "opening-bumper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2736"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "voluntary-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "        data = np.random.rand(1, 244, 244, 3)\n",
    "        yield [data.astype(np.float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "monthly-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_repre = x_train[:10]\n",
    "y_repre = y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "median-armstrong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 200, 1)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_repre.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-oakland",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "finished-oakland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laserlab/coral/git/CompPhys/g2-coral/simulation/Simulator.py:196: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  data = np.array([signal, binnumber, np.array([binary])])\n"
     ]
    }
   ],
   "source": [
    "# generate test data\n",
    "\n",
    "# define parameters\n",
    "types = 10\n",
    "basic = 4\n",
    "rand = np.random.randint(low=0,high=100,size=(types,basic))\n",
    "sourcelist = []\n",
    "\n",
    "# create 50 mixed sources\n",
    "for i in range(types):\n",
    "    randsource = Simulator.simulator(gt=0.5, Nbins=200, width=1., Ndet=1e6, sps=1., laser=1, ther=0, non=0)\n",
    "    sourcelist.append(randsource)\n",
    "\n",
    "# generate 50 data sets per each\n",
    "x_ = []\n",
    "y_ = []\n",
    "datasets = 5\n",
    "for k, source in enumerate(sourcelist):\n",
    "    for i in range(datasets): \n",
    "        data = source.get_data(dist=source.distribution())\n",
    "        x_.append(data[0])\n",
    "        y_.append(data[2])\n",
    "# convert them to np.array\n",
    "x_ = np.array(x_)\n",
    "y_ = np.array(y_)\n",
    "\n",
    "# shuffle\n",
    "i = np.random.permutation(len(x_))\n",
    "x_ = x_[i]\n",
    "y_ = y_[i]\n",
    "\n",
    "# reshape\n",
    "x_train = x_.reshape(x_.shape[0], x_.shape[1], 1)\n",
    "y_train = y_.reshape(y_.shape[0])\n",
    "#loss, accuracy = model.evaluate(x_test, y_test)\n",
    "#print(\"Test accuracy\", accuracy)\n",
    "#print(\"Test loss\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "stunning-beauty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5494 - sparse_categorical_accuracy: 0.4301 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4476 - sparse_categorical_accuracy: 0.5524 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3873 - sparse_categorical_accuracy: 0.6127 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4849 - sparse_categorical_accuracy: 0.5151 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4447 - sparse_categorical_accuracy: 0.5553 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4636 - sparse_categorical_accuracy: 0.5364 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3897 - sparse_categorical_accuracy: 0.6103 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2632 - sparse_categorical_accuracy: 0.7368 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5314 - sparse_categorical_accuracy: 0.4686 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3191 - sparse_categorical_accuracy: 0.6809 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "# train the base_model\n",
    "epochs = 10\n",
    "batch_size = 5\n",
    "\n",
    "base_model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
    "    loss='mse',\n",
    "    metrics=['sparse_categorical_accuracy'],\n",
    ")\n",
    "history = base_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "promising-trustee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp8u51t9oq/assets\n"
     ]
    }
   ],
   "source": [
    "# convert the keras model into TF lite\n",
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('G2model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "seasonal-cheat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape):\n",
    "    # input shape should be (time signal, 1)\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    # 1st con1d layer\n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=4, padding='valid', strides=1, activation='relu')(input_layer)\n",
    "    \n",
    "    # 2nd con1d layer\n",
    "    conv2 = keras.layers.Conv1D(filters=64, kernel_size=4, padding='valid', strides=1, activation='relu')(conv1)\n",
    "\n",
    "    # 3rd con1d layer\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=4, padding='valid', strides=1, activation='relu')(conv2)\n",
    "    \n",
    "    # maxpooling layer\n",
    "    pool = keras.layers.MaxPool1D(pool_size=3, strides=1, padding='valid')(conv3) # keras.layers.GlobalAveragePooling1D()(conv3) #  # \n",
    "    \n",
    "    # flatten layer\n",
    "    flat = keras.layers.Flatten()(pool)\n",
    "    \n",
    "    # fully connected layer to output a binary vector\n",
    "    dense1 = keras.layers.Dense(2, activation='relu')(flat)\n",
    "    #dense2 = keras.layers.Dense(2, activation='relu')(dense1)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=dense1)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=(200,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "boxed-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "LastValueQuantizer = tfmot.quantization.keras.quantizers.LastValueQuantizer\n",
    "MovingAverageQuantizer = tfmot.quantization.keras.quantizers.MovingAverageQuantizer\n",
    "\n",
    "class DefaultDenseQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
    "    # Configure how to quantize weights.\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "          return [(layer.kernel, LastValueQuantizer(num_bits=8, symmetric=True, narrow_range=False, per_axis=False))]\n",
    "\n",
    "    # Configure how to quantize activations.\n",
    "    def get_activations_and_quantizers(self, layer):\n",
    "          return [(layer.activation, MovingAverageQuantizer(num_bits=8, symmetric=False, narrow_range=False, per_axis=False))]\n",
    "\n",
    "    def set_quantize_weights(self, layer, quantize_weights):\n",
    "      # Add this line for each item returned in `get_weights_and_quantizers`\n",
    "      # , in the same order\n",
    "          layer.kernel = quantize_weights[0]\n",
    "\n",
    "    def set_quantize_activations(self, layer, quantize_activations):\n",
    "      # Add this line for each item returned in `get_activations_and_quantizers`\n",
    "      # , in the same order.\n",
    "          layer.activation = quantize_activations[0]\n",
    "\n",
    "    # Configure how to quantize outputs (may be equivalent to activations).\n",
    "    def get_output_quantizers(self, layer):\n",
    "          return []\n",
    "\n",
    "    def get_config(self):\n",
    "          return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "collaborative-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape):\n",
    "    # input shape should be (time signal, 1)\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    # 1st con1d layer\n",
    "    conv1 = quantize_annotate_layer(keras.layers.Conv1D(filters=64, kernel_size=4, padding='valid', strides=1, activation='relu'), DefaultDenseQuantizeConfig())(input_layer)\n",
    "\n",
    "    # 2nd con1d layer\n",
    "    conv2 = keras.layers.Conv1D(filters=64, kernel_size=4, padding='valid', strides=1, activation='relu')(conv1)\n",
    "\n",
    "    # 3rd con1d layer\n",
    "    conv3 = keras.layers.Conv1D(filters=64, kernel_size=4, padding='valid', strides=1, activation='relu')(conv2)\n",
    "    \n",
    "    # maxpooling layer\n",
    "    pool = keras.layers.MaxPool1D(pool_size=3, strides=1, padding='valid')(conv3) # keras.layers.GlobalAveragePooling1D()(conv3) #  # \n",
    "    \n",
    "    # flatten layer\n",
    "    flat = keras.layers.Flatten()(pool)\n",
    "    \n",
    "    # fully connected layer to output a binary vector\n",
    "    dense1 = keras.layers.Dense(2, activation='relu')(flat)\n",
    "    #dense2 = keras.layers.Dense(2, activation='relu')(dense1)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=dense1)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=(200,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "surrounded-avenue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "quantize_layer_7 (QuantizeLa (None, 20)                3         \n",
      "_________________________________________________________________\n",
      "quant_custom_layer_5 (Quanti (None, 20)                425       \n",
      "_________________________________________________________________\n",
      "quant_flatten_7 (QuantizeWra (None, 20)                1         \n",
      "=================================================================\n",
      "Total params: 429\n",
      "Trainable params: 420\n",
      "Non-trainable params: 9\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
    "quantize_annotate_model = tfmot.quantization.keras.quantize_annotate_model\n",
    "quantize_scope = tfmot.quantization.keras.quantize_scope\n",
    "\n",
    "class CustomLayer(tf.keras.layers.Dense):\n",
    "      pass\n",
    "\n",
    "model = quantize_annotate_model(tf.keras.Sequential([\n",
    "   quantize_annotate_layer(CustomLayer(20, input_shape=(20,)), DefaultDenseQuantizeConfig()),\n",
    "   tf.keras.layers.Flatten()\n",
    "]))\n",
    "\n",
    "# `quantize_apply` requires mentioning `DefaultDenseQuantizeConfig` with `quantize_scope`\n",
    "# as well as the custom Keras layer.\n",
    "with quantize_scope(\n",
    "  {'DefaultDenseQuantizeConfig': DefaultDenseQuantizeConfig,\n",
    "   'CustomLayer': CustomLayer}):\n",
    "  # Use `quantize_apply` to actually make the model quantization aware.\n",
    "  quant_aware_model = tfmot.quantization.keras.quantize_apply(model)\n",
    "\n",
    "quant_aware_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "sustainable-sheep",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to clone model. This generally happens if you used custom Keras layers or objects in your model. Please specify them via `quantize_scope` for your calls to `quantize_model` and `quantize_apply`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_apply\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    382\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0mmodel_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clone_model_with_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36m_clone_model_with_weights\u001b[0;34m(model_to_clone)\u001b[0m\n\u001b[1;32m    331\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_clone_model_with_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_clone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m     \u001b[0mcloned_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_clone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m     \u001b[0mcloned_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_clone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36mclone_model\u001b[0;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[1;32m    426\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m     return _clone_sequential_model(\n\u001b[0m\u001b[1;32m    428\u001b[0m         model, input_tensors=input_tensors, layer_fn=clone_function)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[0;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0m_clone_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         if isinstance(layer, InputLayer) else layer_fn(layer))\n\u001b[0m\u001b[1;32m    332\u001b[0m     \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloned_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/models.py\u001b[0m in \u001b[0;36m_clone_layer\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_clone_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize_annotate.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     quantize_config = deserialize_keras_object(\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'quantize_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0m\u001b[1;32m    347\u001b[0m         config, module_objects, custom_objects, printable_module_name)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    295\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprintable_module_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown object: DefaultDenseQuantizeConfig",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-004fc0d70c8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# q_aware stands for for quantization aware.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mq_aware_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# `quantize_model` requires a recompile.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_model\u001b[0;34m(to_quantize)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mannotated_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantize_annotate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_quantize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mquantize_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotated_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py\u001b[0m in \u001b[0;36mquantize_apply\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mmodel_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clone_model_with_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;34m'Unable to clone model. This generally happens if you used custom Keras layers or objects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;34m'in your model. Please specify them via `quantize_scope` for your calls to `quantize_model` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to clone model. This generally happens if you used custom Keras layers or objects in your model. Please specify them via `quantize_scope` for your calls to `quantize_model` and `quantize_apply`."
     ]
    }
   ],
   "source": [
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "# q_aware stands for for quantization aware.\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.traina\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-integration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
